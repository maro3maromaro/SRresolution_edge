## **1\. 全体像**

このプロジェクトは、CD-SEM（臨界寸法走査型電子顕微鏡）画像を高画質化し、CD値（臨界寸法）の計測精度を向上させることを目的とした深層学習パイプラインです。主に以下のPythonファイルで構成されています。

* **config.py**: プロジェクト全体の設定を管理するファイルです。データセットのパス、学習のハイパーパラメータ（エポック数、バッチサイズ、学習率など）、使用するデバイス、モデルのアーキテクチャやそのパラメータ、損失関数の重みなどを一元的に定義します。  
* **utils.py**: データ処理に関連するユーティリティ関数とカスタムクラスが含まれます。特に SEMPatchDataset は、画像の読み込み、中央クロップ、パッチ化、位置合わせ、正規化、データ拡張といった前処理を行い、モデルが学習できる形式のデータを提供します。また、カスタム損失関数 EdgeLoss や CDLoss もここで定義されています。  
* **model.py**: 超解像（画質改善）のためのニューラルネットワークモデルを定義・構築します。BasicSR などの外部ライブラリのモデルを利用しつつ、ライブラリがない環境でも動作するようにフォールバックの簡易モデルも実装されています。build\_model 関数が、config.py の設定に基づいて適切なモデルインスタンスを生成します。  
* **train.py**: モデルの学習プロセス全体を管理する Trainer クラスが定義されています。オプティマイザの設定、学習ループの実行（フォワード計算、損失計算、バックプロパゲーション）、検証ループの実行、学習率の調整、モデルの保存（チェックポインティング）、ログ出力などを担当します。  
* **main.py**: プロジェクト全体のエントリーポイント（実行開始点）です。コマンドライン引数を解釈し、上記各モジュールを連携させて、データ準備、モデル構築、学習、最終評価という一連の処理フローを実行します。

## **2\. main.py を起点とした処理フロー**

main.py を実行すると、以下の順序で処理が進みます。

### **2.1. 初期化フェーズ**

1. **モジュールインポート**:  
   * argparse, pathlib, torch, DataLoader などの基本的なライブラリやPyTorch関連モジュール。  
   * 自作モジュール: config, utils (中の SEMPatchDataset, seed\_everything, CDLoss), train (中の Trainer), model (中の build\_model)。  
2. **コマンドライン引数の解析 (parse\_args 関数)**:  
   * argparse を使用して、スクリプト実行時にユーザーが指定できる引数を定義します。現在は主に \--algo 引数で、使用する超解像アルゴリズム（例: simplesrnet, edgeformer\_edsr\_light など）を選択できます。  
   * 選択されたアルゴリズム名は、後のモデル構築ステップで使用されます。  
3. **乱数シードの固定 (seed\_everything 関数呼び出し)**:  
   * config.py で定義された SEED 値（またはデフォルト値）に基づき、Python標準の random、numpy、torch の乱数生成器のシードを固定します。  
   * これにより、実験結果の再現性を高めることができます。

### **2.2. データ準備フェーズ**

1. **設定読み込み**:  
   * config.py から、学習データおよび検証データのディレクトリパス (TRAIN\_LOW\_DIR, VAL\_HIGH\_DIRなど)、画像処理に関する設定 (CENTRAL\_CROP\_HEIGHT, CENTRAL\_CROP\_WIDTH, PATCH\_SIZE)、データローダーに関する設定 (BATCH\_SIZE, NUM\_WORKERS) などを読み込みます。  
2. **データセットオブジェクトの作成 (SEMPatchDataset クラス)**:  
   * 学習用 (train\_ds) と検証用 (val\_ds) のデータセットオブジェクトを utils.py の SEMPatchDataset クラスを用いて作成します。  
   * SEMPatchDataset の主な処理:  
     * **ファイル収集**: 指定されたディレクトリから、config.FILE\_PREFIX と末尾 SUFFIX\_LEN 文字で低解像度(LR)画像と高解像度(HR)画像のペアを探索・マッチングします。  
     * **画像読み込み (\_\_getitem\_\_)**: cv2.imread でLR画像とHR画像をグレースケールで読み込みます。  
     * **中央クロップ (\_get\_central\_crop)**: 読み込んだ画像から、config.CENTRAL\_CROP\_HEIGHT と config.CENTRAL\_CROP\_WIDTH で指定された中央領域を切り出します。  
     * **ランダムパッチ生成**: 切り出された中央領域内から、config.PATCH\_SIZE で指定されたサイズの正方形パッチをランダムな位置から切り出します。  
     * **位置合わせ (\_align\_patch)**: LRパッチとHRパッチ間のサブピクセルレベルのズレを skimage.registration.phase\_cross\_correlation を用いて検出し、LRパッチをHRパッチに合わせてアフィン変換します。  
     * **データ拡張**: 50%の確率で左右反転を行います。  
     * **正規化とテンソル変換**: パッチのピクセル値を \[-1, 1\] の範囲に正規化し、PyTorchのテンソル形式 ((1, patch\_size, patch\_size)) に変換します。  
     * repeats 引数により、1つの画像ペアから複数回パッチをサンプリングすることでデータ量を擬似的に増やします（学習時）。  
3. **データローダーオブジェクトの作成 (DataLoader クラス)**:  
   * 作成されたデータセットオブジェクト (train\_ds, val\_ds) をPyTorchの DataLoader に渡して、学習用 (train\_loader) と検証用 (val\_loader) のデータローダーを作成します。  
   * DataLoader の役割:  
     * **バッチ化**: データを config.BATCH\_SIZE で指定された数のミニバッチにまとめます。  
     * **シャッフル** (学習時のみ): 各エポックの開始時にデータの順序をランダムに並び替えます。  
     * **並列読み込み**: num\_workers で指定された数のCPUプロセスを使ってデータの読み込みと前処理をバックグラウンドで並列実行し、GPUの待ち時間を減らします。  
     * pin\_memory=True: GPUへのデータ転送を高速化する設定です（CUDAが利用可能な場合）。

### **2.3. モデル準備フェーズ**

1. **モデル構築 (build\_model 関数)**:  
   * model.py で定義された build\_model 関数を呼び出します。  
   * 引数として、コマンドラインで指定されたアルゴリズム名 (args.algo) を渡します。  
   * build\_model 関数の内部処理:  
     * 指定されたアルゴリズム名に対応する設定を config.MODEL\_CONFIGS から取得します（例: チャネル数、ブロック数など）。  
     * アルゴリズム名に応じて、適切なモデルクラス（例: SimpleSRNet, EDSR, RDN など、またはそれらを組み合わせた派生モデル）を、取得したパラメータで初期化します。  
     * \_import\_or\_fallback ヘルパー関数により、BasicSR などの外部ライブラリのモデルコンポーネントのインポートを試み、失敗した場合は model.py 内に定義された簡易的なフォールバック実装を使用します。  
   * 構築されたモデルオブジェクトが返されます。この時点では、モデルの重みは初期化された状態です。

### **2.4. 学習準備フェーズ (Trainer クラスの初期化)**

1. **保存ディレクトリ作成**:  
   * 学習の成果物（学習済みモデルの重み、ログなど）を保存するためのディレクトリ（例: runs/simplesrnet/）を作成します。  
2. **Trainer オブジェクトの作成**:  
   * train.py で定義された Trainer クラスのインスタンスを作成します。  
   * Trainer のコンストラクタに以下の主要な情報を渡します:  
     * model: 2.3で構築されたモデルオブジェクト。  
     * train\_loader: 学習用データローダー。  
     * val\_loader: 検証用データローダー。  
     * device: config.DEVICE で指定された学習デバイス ('cuda' または 'cpu')。モデルはこのデバイスに転送されます。  
     * save\_dir: 保存先ディレクトリのパス。  
     * epochs: config.EPOCHS で指定された総学習エポック数。  
     * lr: config.LEARNING\_RATE で指定された初期学習率。  
   * Trainer の初期化処理 (\_\_init\_\_) 内部:  
     * オプティマイザ (torch.optim.AdamW) を設定します。  
     * 学習率スケジューラ (CosineAnnealingLR や StepLR など、config.py の設定に基づく) を設定します。  
     * 損失関数群を初期化し、デバイスに転送します:  
       * nn.L1Loss (L1損失)  
       * StructuralSimilarityIndexMeasure (SSIM算出用、損失としては 1-SSIM を使用)  
       * EdgeLoss (カスタムエッジ損失)  
       * CDLoss (カスタムCD損失)  
     * 各損失の重みを config.LOSS\_WEIGHTS から取得します。  
     * Mixed Precision (FP16) 学習のための torch.cuda.amp.GradScaler を初期化します (CUDA使用時のみ)。  
     * モデルチェックポインティングのための変数 (monitor\_metric, best\_metric\_val など) を初期化します。

### **2.5. 学習実行フェーズ (Trainer.train メソッド)**

1. trainer.train() メソッドが呼び出され、学習プロセスが開始されます。  
2. 指定された epochs 数だけループが繰り返されます。各エポックで以下の処理が行われます。  
   * **学習 (\_train\_one\_epoch メソッド)**:  
     1. model.train(): モデルを学習モードに設定します (DropoutやBatchNormalizationの挙動が学習用に変わります)。  
     2. train\_loader からミニバッチ単位で学習データ (LR画像パッチ lr\_img と HR画像パッチ hr\_img) を取り出します。  
     3. データとモデルを学習デバイス (self.device) に転送します。  
     4. torch.cuda.amp.autocast() コンテキスト内 (CUDA使用かつFP16有効時) で以下を実行:  
        * **フォワードパス**: sr \= self.model(lr\_img) を実行し、LRパッチから超解像(SR)パッチを生成します。  
        * **損失計算 (\_calculate\_combined\_loss メソッド)**: 生成されたSRパッチと教師HRパッチを比較し、複数の損失（L1, 1-SSIM, EdgeLoss, CDLoss）を計算し、config.LOSS\_WEIGHTS で指定された重みで加重合計して最終的な損失値 loss を得ます。  
     5. **バックプロパゲーション**:  
        * self.optim.zero\_grad(): 前のステップの勾配をクリアします。  
        * self.scaler.scale(loss).backward() (FP16時): 損失に基づいて勾配を計算します。FP16の場合はスケーリングされます。  
        * self.scaler.step(self.optim) (FP16時): オプティマイザを使ってモデルのパラメータを更新します。FP16の場合はアンダーフローを防ぐためにスケーリングされた勾配を扱います。  
        * self.scaler.update() (FP16時): GradScalerのスケールファクタを次のステップのために更新します。  
        * (FP16でない場合、またはCPUの場合): loss.backward() と self.optim.step() が直接呼び出されます。  
     6. 一定ステップごとに学習の進捗（現在のエポック、ステップ、損失値など）をコンソールに出力します。  
     7. エポック全体の平均学習損失を計算して表示します。  
   * **検証 (\_validate\_one\_epoch メソッド)**:  
     1. model.eval(): モデルを評価モードに設定します。  
     2. torch.no\_grad() コンテキスト内で勾配計算を無効化します。  
     3. val\_loader からミニバッチ単位で検証データを取り出します。  
     4. フォワードパスを実行し、SRパッチを生成します。  
     5. SRパッチとHRパッチを用いて、学習時と同様に総合損失を計算します。  
     6. さらに、評価指標である PSNR (torchmetrics.functional.peak\_signal\_noise\_ratio)、SSIM (self.ssim\_metric を使用)、および CDLoss (self.cd\_loss\_fn) を計算します。  
     7. エポック全体の平均検証損失、平均PSNR、平均SSIM、平均CDLossを計算して表示します。  
   * **学習率スケジューラの更新**:  
     * 設定されていれば、self.scheduler.step() を呼び出し、学習率を更新します。スケジューラの種類によっては検証損失などのメトリックを引数に取る場合もあります。  
   * **モデルチェックポインティング**:  
     * 現在のエポックの検証結果 (val\_metrics) から config.MONITOR\_METRIC で指定された指標（例: val\_cdloss）の値を取得します。  
     * config.MONITOR\_MODE ('min' または 'max') に基づいて、これまでの最良の指標値 (self.best\_metric\_val) と比較します。  
     * もし現在の指標値が最良値を更新した場合、self.best\_metric\_val を更新し、現在のモデルの重み (self.model.state\_dict()) を self.best\_model\_path (例: runs/simplesrnet/best\_model\_on\_val\_cdloss.pth) に保存します。  
3. 全ての学習エポックが完了すると、trainer.train() メソッドは終了します。

### **2.6. 最終評価フェーズ (evaluate\_final\_model 関数)**

1. 学習プロセスが完了した後、main 関数は最終評価のセクションに進みます。  
2. Trainer オブジェクトが保持している best\_model\_path（学習中に保存された最も性能の良かったモデルのパス）を取得します。  
3. もしベストモデルのファイルが存在すれば、main.py 内で定義されている evaluate\_final\_model 関数を呼び出します。  
   * evaluate\_final\_model 関数は、指定されたパスからベストモデルの重みを読み込み、再度検証データセット (val\_loader) を用いて評価を実行します。  
   * 最終的な PSNR、SSIM、CDLoss の値をコンソールに出力します。  
   * これにより、学習プロセス全体を通して得られた最良のモデルの客観的な性能を確認できます。

以上が、提供されたコード全体の主要な処理の流れです。このパイプラインは、設定の柔軟性、データ処理の効率性、多様なモデルの試行、そして体系的な学習と評価を可能にするように設計されています。